{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap.umap_ as umap\n",
    "import hdbscan\n",
    "import pickle\n",
    "from sklearn.cluster import DBSCAN\n",
    "from umap import UMAP\n",
    "from img2vec_pytorch import Img2Vec\n",
    "from PIL import Image\n",
    "import torch\n",
    "import time\n",
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "# preproocessing of images\n",
    "def data_preprocess(paths):\n",
    "    data = []\n",
    "    size = (100, 150)\n",
    "    for img in paths:\n",
    "        try:\n",
    "            img_path = img.replace('\\n', '')\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) #read images in grayscale\n",
    "            image_small = cv2.resize(image, size, interpolation = cv2.INTER_AREA) #resize images to unified size (in our case 100 X 150)\n",
    "            image_bin = cv2.adaptiveThreshold(image_small, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                cv2.THRESH_BINARY,11,2) #binarization (threshold value is a gaussian-weighted sum of the neighbourhood values minus the constant C)\n",
    "            # every image have binary format with 0 and 1\n",
    "            bin_new = []\n",
    "            for i in image_bin:\n",
    "                i_new = []\n",
    "                for e in i:\n",
    "                    if e == 255:\n",
    "                        e = 1\n",
    "                        i_new.append(e)\n",
    "                    else:\n",
    "                        e = 0\n",
    "                        i_new.append(e)\n",
    "                bin_new.append(i_new)            \n",
    "            # print(bin_new)\n",
    "            roi = np.array(bin_new, dtype = np.uint8).reshape(-1) #mask image format in type [x0, x1, x2 ...]\n",
    "            # print(roi)\n",
    "            # list\n",
    "            mask = roi.tolist()\n",
    "            # add filename to the end of list\n",
    "            row_data_list = mask + list([img])\n",
    "            # get array of data\n",
    "            data.append(row_data_list)\n",
    "        except:\n",
    "            # print(img)\n",
    "            with open('logs_dir.log', 'a', encoding = 'utf-8') as f:\n",
    "                f.write(f'{img}\\n')\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "# IMG2VEC\n",
    "# get file paths from dataframe\n",
    "def clear_paths(df):\n",
    "    df_to_list = df.loc[:, 15000].tolist()\n",
    "    paths_for_embed = []\n",
    "    for d in df_to_list:\n",
    "        clear_path = d.replace('\\n', '')\n",
    "        paths_for_embed.append(clear_path)\n",
    "    return paths_for_embed\n",
    "\n",
    "# get image embeddings from dataframe\n",
    "def vec_img(paths):\n",
    "    # img2vec = Img2Vec(cuda=False)\n",
    "    img2vec = Img2Vec(cuda=True)\n",
    "    size = (100, 150)\n",
    "    vec_list = []\n",
    "    for p in paths:\n",
    "        image = cv2.imread(p, cv2.IMREAD_GRAYSCALE) #read images in grayscale\n",
    "        image_small = cv2.resize(image, size, interpolation = cv2.INTER_AREA) #resize images to unified size (in our case 100 X 150)\n",
    "        image_bin = cv2.adaptiveThreshold(image_small, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                    cv2.THRESH_BINARY,11,2) # get mask with values 0 and 1\n",
    "        img_rgb = cv2.cvtColor(image_bin, cv2.COLOR_BGR2RGB) #change to RGB colour space\n",
    "        pil_img = Image.fromarray((img_rgb * 255).astype(np.uint8)) #convert to pillow object\n",
    "        # print(pil_img)\n",
    "        vectors = img2vec.get_vec(pil_img, tensor=True) #img2vec get img PIL object\n",
    "        vec_list.append(vectors)\n",
    "    return vec_list\n",
    "\n",
    "# get arrays from tensors\n",
    "def tensor_to_array(vec_list):\n",
    "    arr_list = []\n",
    "    for v in vec_list:\n",
    "        numpy_arr = v.numpy()\n",
    "        resh_array = numpy_arr.reshape(-1)\n",
    "        arr_list.append(resh_array)\n",
    "    return arr_list\n",
    "\n",
    "# functions for data vis\n",
    "#get resize images in numpy arrays\n",
    "def img_reshape(img):\n",
    "    img = Image.open(img).convert('RGB')\n",
    "    img = img.resize((200,300))\n",
    "    img = np.asarray(img) \n",
    "    return img\n",
    "\n",
    "# get numpy arrays from image list\n",
    "def get_array(random_set):\n",
    "    img_arr = [] #image array as numpy array\n",
    "    for i in random_set:\n",
    "        try:\n",
    "            img_arr.append(img_reshape(i)) \n",
    "        except FileNotFoundError: \n",
    "            continue\n",
    "    return img_arr\n",
    "\n",
    "# function for image visualization from random sample (any 10 images)\n",
    "def show_sample(img_arr, path_list):\n",
    "    rows=2\n",
    "    cols = 5\n",
    "    img_count = 0\n",
    "    files_count = 0\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20,10))\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):        \n",
    "            if img_count < len(img_arr):\n",
    "                axes[i, j].imshow(img_arr[img_count])\n",
    "                axes[i, j].set_ylabel(str(path_list[files_count]), fontsize = 5)\n",
    "                img_count+=1\n",
    "                files_count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "# clustering with UMAP + HDBSCAN\n",
    "with open('your_image_paths.txt') as f:\n",
    "    paths = f.readlines()\n",
    "data = data_preprocess(paths)\n",
    "df = pd.DataFrame(data)\n",
    "paths_for_embed = clear_paths(df)\n",
    "\n",
    "# image feature extraction with img2vec Ð¸ resnet\n",
    "start_time = time.time()\n",
    "vec_list = vec_img(paths_for_embed)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Elapsed time: ', elapsed_time)\n",
    "\n",
    "# convert tensors to numpy arrays\n",
    "arr_list = tensor_to_array(vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP with image vectorizing data (img2vec)\n",
    "# MAIN\n",
    "vec_embedding = umap.UMAP(\n",
    "    n_neighbors=5,\n",
    "    min_dist=0.1,\n",
    "    metric='correlation',\n",
    "    n_components = 2,\n",
    "    random_state=42,\n",
    ").fit_transform(arr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.scatter(vec_embedding[:, 0], vec_embedding[:, 1], cmap = 'Spectral')\n",
    "plt.show()\n",
    "# plt.savefig(\"cluster_umap_img2vec.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering of all image data and assignment of classes\n",
    "# MAIN\n",
    "labels_vec = hdbscan.HDBSCAN(\n",
    "    min_samples=50,\n",
    "    min_cluster_size=50,\n",
    ").fit_predict(vec_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save label list of sample images to file 'pickle'\n",
    "# with open('labels_vec_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(labels_vec, f)\n",
    "\n",
    "# save embeddings list of images to file 'pickle'\n",
    "# with open('vec_embeddings_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(vec_embedding, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "clustered_vec = (labels_vec >= 0)\n",
    "plt.scatter(vec_embedding[~clustered_vec, 0],\n",
    "            vec_embedding[~clustered_vec, 1],\n",
    "                    c=(0.1, 0.1, 0.1),\n",
    "            s=0.1,\n",
    "            alpha=0.8)\n",
    "\n",
    "plt.scatter(vec_embedding[clustered_vec, 0],\n",
    "            vec_embedding[clustered_vec, 1],\n",
    "            c = labels_vec[clustered_vec],\n",
    "            s=0.1,\n",
    "            cmap='Spectral')\n",
    "# plt.savefig(\"cluster_42272_dbscan_img2vec.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unique values of cluster's labels\n",
    "uniq_labels, counts = np.unique(labels_vec, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.asarray((uniq_labels, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_df = pd.DataFrame({\"Values\": uniq_labels, \"Counts\": counts})\n",
    "sort_df.sort_values(by = 'Counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datavis of propotion of clusters\n",
    "ax = sort_df.sort_values(by = 'Counts', ascending=False).groupby(['Values']).sum().plot(figsize=(20,20), \n",
    "                                                                                        kind = 'pie', y = 'Counts', \n",
    "                                                rotatelabels=True, title = 'ÐÐ¾Ð»Ð¸ÑÐµÑÑÐ²Ð¾ Ð¸Ð·Ð¾Ð±ÑÐ°Ð¶ÐµÐ½Ð¸Ð¹ Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¼ ÐºÐ»Ð°ÑÑÐµÑÐµ',\n",
    "                                                                                       cmap = 'Spectral')\n",
    "# plt.savefig(\"common_clusters_diagram.png\", dpi = 100)\n",
    "# we choosed the biggest cluster with pages containing bibliographic records (number 20 in our sample data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataframe with cluster's labels and linked filenames\n",
    "# MAIN\n",
    "df_clusters = pd.DataFrame({\"Filepath\": paths_for_embed, \"Cluster\": labels_vec})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at cluster 20 (the biggest one) with bibliographic records\n",
    "c_20 = df_clusters.loc[((df_clusters['Cluster'] == 20))]\n",
    "c_20_example = c_20.sample(n = 10)\n",
    "c_20_list = c_20_example[\"Filepath\"].tolist()\n",
    "c_20_arr = get_array(c_20_list)\n",
    "c_20_show = show_sample(c_20_arr, c_20_list)\n",
    "# plt.savefig(\"cluster_20.jpg\", dpi = 100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
